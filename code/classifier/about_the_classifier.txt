The used classifier is a multiplayer perceptron with one input layer (of size determined by the macro INPUT_SIZE in the cpp codes),
one hidden layer and one output layer of size 1 (output value 1 means the image is tampered, 0 means the image is authentic).

This implementation is purely made by the authors, no special libraries, packages or modules were used. It was tested
with the classic MNIST dataset on the site kaggle.com and it appears to be bug-free (or at least without any critical errors).
It was able to get a score of about 0.94 on the site.

The implementation is divided in two programs:

train.cpp: The training program. It assumes the existence of a training file called train.dat in the working directory.
train.dat should be formatted as a matrix with one line per image. The first element of each line is the image class/label (0 means authentic,
1 means tampered). The following INPUT_SIZE elements are the features of each image. Script processData.py outputs the train.dat and test.dat
in the expected format.
The train program expects three arguments: an integer which represents the number of neurons to be used in the hidden layer, and two floating
point values: the step parameter (commonly represented by the greek letter eta) for the backpropagation algorithm and a threshold for
the mean squared error of the classifier. The training stops only when the MSE is less than the given threshold. The MSE is printed
on the standard output after each iteration of the algorithm. When it stops, a .dat file is created containing the final parameters
of the classifier. It's name is classifier-X-Y-Z-A.dat, where X, Y and Z are the parameters mentioned above, and A is the final
accuracy of the classifier for the training set.

test.cpp: The testing program. It receives as parameter a .dat file generated by the training program. It also assumes the existence of a
test.dat file which contains the instances to be used for the test.

Both programs make use of the in perceptron.cpp, where the core implementation of the classifier is.
Use the Makefile to compile the programs.
